{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openpyxl import load_workbook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from chord import Chord\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic functions\n",
    "\n",
    "def data_deal(path, fileList, paraList, excelName, alignment):\n",
    "    data_final = {}\n",
    "    len_min = 999999\n",
    "    for fileName in fileList:\n",
    "        data_tmp = pd.read_excel(path + fileName)\n",
    "        data_tmp = data_tmp[paraList]\n",
    "        def func(x):\n",
    "            if ((isinstance(x, float) and x<=0) or (isinstance(x, int) and x<=0) or np.isnan(x)): \n",
    "                return np.nan\n",
    "            else:\n",
    "                return x\n",
    "        data_tmp = data_tmp.applymap(func).dropna(axis = 0).reset_index(drop=True)\n",
    "        data_tmp = deal_outlier(data_tmp).reset_index(drop=True)\n",
    "        len_min = data_tmp.shape[0] if data_tmp.shape[0] < len_min else len_min\n",
    "        sheet_name = fileName.split('.')[:-1]\n",
    "        data_final.update({sheet_name: data_tmp})\n",
    "    for fileName in fileList:\n",
    "        if alignment == 1:\n",
    "            data_final[sheet_name] = data_alignment(data_final[sheet_name], len_min).reset_index(drop=True)\n",
    "    write_excel(\"/\".join(path.split(\"/\")[:-2]), data_final, excelName, paraList)\n",
    "    return\n",
    "\n",
    "\n",
    "def deal_outlier(data_orig):\n",
    "    index_list = []\n",
    "    for key in data_orig.columns:\n",
    "        Q1 = np.percentile(data_orig[key], 25)\n",
    "        Q3 = np.percentile(data_orig[key], 75)\n",
    "        IQR = Q3 - Q1\n",
    "        inlier = 1.5 * IQR\n",
    "        outlier = 3 * IQR\n",
    "        for index, value in enumerate(data_orig[key]):\n",
    "            if value < Q1-outlier or value > Q3+outlier:\n",
    "                index_list.append(index)\n",
    "        data_new = data_orig.drop(index = index_list)\n",
    "    return data_new\n",
    "    \n",
    "\n",
    "\n",
    "def data_alignment(df_T, lenth_min, group_name):\n",
    "    if group_name in ['Control', 'T2DMInsulin2W', 'T2DMLiraglutide2W']:\n",
    "        para = df_T.columns[0]\n",
    "        df_T = df_T.loc[sorted(np.argsort(df_T[para])[-lenth_min:])]\n",
    "    elif group_name in ['T2DM', 'T2DMInsulin1W', 'T2DMLiraglutide1W']:\n",
    "        para = df_T.columns[0]\n",
    "        df_T = df_T.loc[sorted(np.argsort(df_T[para])[:lenth_min])]\n",
    "    return df_T\n",
    "\n",
    "\n",
    "def write_excel(path, data_dict, excelName, paraList):\n",
    "    data_para = {}\n",
    "    for para in paraList:\n",
    "        data_para[para] = {}\n",
    "    book = load_workbook(path + excelName)\n",
    "    writer = pd.ExcelWriter(path + excelName, engine='openpyxl')\n",
    "    for key, value in data_dict.items():\n",
    "        for para in paraList:\n",
    "            data_para[para][key] = value[para]\n",
    "        writer.book = book\n",
    "        value.to_excel(writer, key, index = False)\n",
    "        writer.save()\n",
    "    for para in paraList:\n",
    "        writer.book = book\n",
    "        pd.DataFrame(data_para[para]).to_excel(writer, para.replace(\"[\", \"(\").replace(\"]\", \")\").replace(\"/\", \"|\"), index = False)\n",
    "        writer.save()\n",
    "    writer.close() \n",
    "\n",
    "\n",
    "def lcm(x, y):\n",
    "    if x > y:\n",
    "        greater = x\n",
    "    else:\n",
    "        greater = y\n",
    "    while(True):\n",
    "        if((greater % x == 0) and (greater % y == 0)):\n",
    "            lcm = greater\n",
    "            break\n",
    "        greater += 1\n",
    "    return lcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing data for drawing pie charts\n",
    "\n",
    "path = \"Your Path\"\n",
    "fileList = os.listdir(path)\n",
    "\n",
    "list_pie = [\"Oxygenized hemoglobin concentration [µM]\", \"Reduced hemoglobin concentration [µM]\"]    \n",
    "data_deal(path, fileList, list_pie, \"/dataForPie.xlsx\", alignment = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing data for subsequent processing\n",
    "\n",
    "para_list = ['RBC tissue fraction [%]', 'Total hemoglobin concentration [µM]', 'Oxygenized hemoglobin concentration [µM]', 'Reduced hemoglobin concentration [µM]', 'Oxygen saturation [%]', 'Speed resolved perfusion [% RBC x mm/s], < 1 mm/s',  '1-10 mm/s', '> 10 mm/s', 'Total perf', 'Conventional perfusion [PU]']\n",
    "data_deal(path, fileList, para_list, \"/dataProcessed.xlsx\", alignment = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing data for drawing bubble charts\n",
    "\n",
    "def data_alignment2(dict_T, lenth_min):\n",
    "    for key in dict_T.keys():\n",
    "        if key in ['Control', 'T2DMInsulin2W', 'T2DMLiraglutide2W']:\n",
    "            dict_T[key] = dict_T[key].loc[sorted(np.argsort(dict_T[key])[-lenth_min:])].reset_index(drop=True)\n",
    "        elif key in ['T2DM', 'T2DMInsulin1W', 'T2DMLiraglutide1W']:\n",
    "            dict_T[key] = dict_T[key].loc[sorted(np.argsort(dict_T[key])[:lenth_min])].reset_index(drop=True)\n",
    "    return dict_T\n",
    "\n",
    "group_list = ['Control', 'T2DM', 'T2DMInsulin1W', 'T2DMInsulin2W', 'T2DMLiraglutide1W', 'T2DMLiraglutide2W']\n",
    "\n",
    "book = load_workbook(path + '/dataForBubble.xlsx')\n",
    "writer = pd.ExcelWriter(path + '/dataForBubble.xlsx', engine='openpyxl')\n",
    "\n",
    "for para in para_list:\n",
    "    data_dict = {}\n",
    "    len_min = 9999\n",
    "    list_num = \"Number of samples per group\"\n",
    "    for index, group in enumerate(group_list):\n",
    "        use_columns = list(range(index*list_num, (index+1)*list_num))\n",
    "        data_tmp = pd.read_excel(path + \"/dataProcessed.xlsx\", sheet_name = para, usecols=use_columns)\n",
    "        list_tmp = []\n",
    "        for key in data_tmp.columns:\n",
    "            list_tmp.extend([x for x in data_tmp[key] if ~np.isnan(x)])\n",
    "        len_min = len(list_tmp) if len(list_tmp) < len_min else len_min\n",
    "        data_dict[group] = pd.Series(list_tmp)\n",
    "    data_dict = data_alignment2(data_dict, len_min)\n",
    "    writer.book = book\n",
    "    pd.DataFrame(data_dict).to_excel(writer, para, index = False)\n",
    "    print(f\"{para} down\")\n",
    "writer.close() \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing data for drawing heat map\n",
    "\n",
    "book = load_workbook(path + '/dataForHeatmap.xlsx')\n",
    "writer = pd.ExcelWriter(path + '/dataForHeatmap.xlsx', engine='openpyxl')\n",
    "\n",
    "for index, group in enumerate(group_list):\n",
    "    data_dict = {}\n",
    "    len_min = 9999\n",
    "    list_num = \"Number of samples per group\"\n",
    "    for para in para_list:\n",
    "        data_dict[para] = []\n",
    "        \n",
    "    for i in range(list_num):\n",
    "        sheet_name = fileList[index*list_num + i].split('.')[:-1]\n",
    "        data_tmp = pd.read_excel(path + \"/dataProcessed.xlsx\", sheet_name = sheet_name)\n",
    "        for para in data_tmp.columns:\n",
    "            data_dict[para].extend(data_tmp[para].values.tolist())\n",
    "    \n",
    "    writer.book = book\n",
    "    pd.DataFrame(data_dict).to_excel(writer, group, index = False)\n",
    "    print(f\"{group} down\")\n",
    "writer.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for drawing chord diagram\n",
    "\n",
    "Chord.user = \"your username\"\n",
    "Chord.key = \"your key\"\n",
    "\n",
    "def draw_chord(chord_data, names, colors, group, part_num, path):\n",
    "    chord = Chord(chord_data,\n",
    "                  names,\n",
    "                  colors=colors,\n",
    "                  opacity=0.8, \n",
    "                  padding=0.01, \n",
    "                  width=2500, \n",
    "                  label_color=\"#454545\", \n",
    "                  curved_labels = True, \n",
    "                  wrap_labels=False, \n",
    "                  margin=70, \n",
    "                  reverse_gradients=False,\n",
    "                  credit=False,\n",
    "                  font_size=\"36px\",\n",
    "                  font_size_large=\"36px\",\n",
    "                  details=[],\n",
    "                  details_thumbs=[], \n",
    "                  thumbs_width=85,\n",
    "                  thumbs_margin=5,\n",
    "                  thumbs_font_size=14,\n",
    "                  popup_width=350,\n",
    "                  details_separator=\", \",\n",
    "                  divide=True,\n",
    "                  divide_idx=part_num,\n",
    "                  divide_size=0.5, \n",
    "                  divide_left_label=\"SO2(%)\",\n",
    "                  divide_right_label=\"BP(PU)\",\n",
    "                  instances=0,\n",
    "                  conjunction=\"and\",\n",
    "                  verb=\"occur together in\",\n",
    "                  noun=\"instances\", \n",
    "                  symmetric=True,\n",
    "                  title=group,\n",
    "                  arc_numbers=False, \n",
    "                  inner_radius_scale=0.39,\n",
    "                  outer_radius_scale=1.1, \n",
    "                  allow_download=True,        \n",
    "                 )\n",
    "    chord.to_html(path + '/chord/' + group + '.html')\n",
    "    chord.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for drawing chord diagram\n",
    "\n",
    "def dealAndchord(data_select, path, filename, path_to):\n",
    "    groups = ['Control', 'T2DM', 'Ins 1w', 'Ins 2w', 'Lirag 1w', 'Lirag 2w']\n",
    "    colors = ['#e41a1c', '#4F3F84', \"#7400B8\", '#984ea3',\"#5E60CE\", \"#5684D6\", \"#56CFE1\", \"#64DFDF\", \"#80FFDB\",\"#b7f8db\" ]\n",
    "    colors.reverse()\n",
    "\n",
    "    for index, value in enumerate(groups):\n",
    "        colors_final = []\n",
    "        print(value)\n",
    "        names = []\n",
    "        matrx_shape = []\n",
    "        for i in data_select.keys():\n",
    "            matrx_shape.append(data_select[i][2])\n",
    "        matrx_count = np.array([[0] * matrx_shape[0] for i in range(matrx_shape[1])])\n",
    "        data_o = []\n",
    "        flag = 0\n",
    "        for i in data_select.keys():\n",
    "            usecols = range(index*9, index*9+9)\n",
    "            data_tmp = pd.read_excel(path + filename, sheet_name = i, usecols=usecols)\n",
    "            divider = (data_select[i][1] - data_select[i][0]) / data_select[i][2]\n",
    "            if flag == 0:\n",
    "                start = data_select[i][0]\n",
    "                while start < data_select[i][1]:\n",
    "                    names.append(str(start) + '-' + str(start+divider))\n",
    "                    start += divider\n",
    "                    colors_final += colors\n",
    "                flag = 1\n",
    "            else:\n",
    "                start = data_select[i][1]\n",
    "                colors.reverse()\n",
    "                while start > data_select[i][0]:\n",
    "                    names.append(str(start) + '-' + str(start-divider))\n",
    "                    start -= divider\n",
    "                    colors_final += colors\n",
    "                colors.reverse()\n",
    "            data_o.append([math.ceil((a-data_select[i][0])/divider) for a in data_tmp.values[~np.isnan(data_tmp.values)]])\n",
    "        for x,y in zip(data_o[0], data_o[1]):\n",
    "            x = matrx_shape[0] if x > matrx_shape[0] else x\n",
    "            y = matrx_shape[1] if y > matrx_shape[1] else y\n",
    "            matrx_count[y-1][matrx_shape[0]-x] += 1\n",
    "        chord_data = np.append(np.append(np.array([[0] * matrx_shape[0] for i in range(matrx_shape[0])]), matrx_count.T,axis=1),np.append(matrx_count, np.array([[0] * matrx_shape[1] for i in range(matrx_shape[1])]) ,axis=1),axis=0).tolist()\n",
    "        draw_chord(chord_data, names, colors_final, value, matrx_shape[0], path_to)\n",
    "    data_demo = np.array([[10] * (matrx_shape[0]+matrx_shape[1]) for i in range(matrx_shape[0]+matrx_shape[1])]).tolist()\n",
    "    print(colors_final)\n",
    "    draw_chord(data_demo, names, colors_final, 'demo', matrx_shape[0], path_to)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_select = {\"Conventional perfusion (PU)\":[0,1000,50], \"Oxygen saturation (%)\":[0,100,50]}\n",
    "filename = path + \"/dataProcessed.xlsx\"\n",
    "dealAndchord(data_select, path, filename, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of four dimensionless methods\n",
    "# And processing data for drawing 3D images\n",
    "        \n",
    "for data_group in group_list:\n",
    "    data_orig = pd.read_excel(path+\"/dataProcessed.xlsx\", header=0, sheet_name=data_group)\n",
    "    features = data_orig.columns.values.tolist()\n",
    "    column_num = data_orig.shape[1]\n",
    "    dict_tmp = {}\n",
    "    for key in features:\n",
    "        dict_tmp[key] = [x for x in data_orig[key] if ~np.isnan(x)]\n",
    "\n",
    "    data_lcm = 1\n",
    "    for key in features:\n",
    "        data_lcm = lcm(len(dict_tmp[key]), data_lcm)\n",
    "\n",
    "    dict_new = {}\n",
    "    for key in features:\n",
    "        tmp = []\n",
    "        for i in range(len(dict_tmp[key])):\n",
    "            for k in range(int(data_lcm/len(dict_tmp[key]))):\n",
    "                tmp.append(dict_tmp[key][i])\n",
    "        dict_new[key] = tmp\n",
    "\n",
    "\n",
    "\n",
    "    # Min-Max\n",
    "    data_total = []\n",
    "    for i in range(data_lcm):\n",
    "        for index, value in enumerate(features):\n",
    "            data_total.append([(i+1)*60/data_lcm, index, (dict_new[value][i]-min(dict_new[value]))/(max(dict_new[value])-min(dict_new[value]))])\n",
    "    \n",
    "    # Z-score\n",
    "    data_total2 = []\n",
    "    max_num = 0\n",
    "    min_num = 1\n",
    "    for i in range(data_lcm):\n",
    "        for index, value in enumerate(features):\n",
    "            if (max(dict_new[value])-np.mean(dict_new[value]))/np.std(dict_new[value]) > max_num:\n",
    "                max_num = (max(dict_new[value])-np.mean(dict_new[value]))/np.std(dict_new[value])\n",
    "            if (min(dict_new[value])-np.mean(dict_new[value]))/np.std(dict_new[value]) < min_num:\n",
    "                min_num = (min(dict_new[value])-np.mean(dict_new[value]))/np.std(dict_new[value])\n",
    "            data_total2.append([(i+1)*60/data_lcm, index, (dict_new[value][i]-np.mean(dict_new[value]))/np.std(dict_new[value])])\n",
    "\n",
    "    # Median\n",
    "    data_total3 = []\n",
    "    max_num = 0\n",
    "    for i in range(data_lcm):\n",
    "        for index, value in enumerate(features):\n",
    "            if dict_new[value][i]/np.median(dict_new[value]) > max_num:\n",
    "                max_num = dict_new[value][i]/np.median(dict_new[value])\n",
    "            data_total3.append([(i+1)*60/data_lcm, index, dict_new[value][i]/np.median(dict_new[value])])\n",
    "\n",
    "    # Norm\n",
    "    data_total4 = []\n",
    "    max_num = 0\n",
    "    for i in range(data_lcm):\n",
    "        for index, value in enumerate(features):\n",
    "            if dict_new[value][i]/np.linalg.norm(dict_new[value]) > max_num:\n",
    "                max_num = dict_new[value][i]/np.linalg.norm(dict_new[value])\n",
    "            data_total4.append([(i+1)*60/data_lcm, index, dict_new[value][i]/np.linalg.norm(dict_new[value])])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
